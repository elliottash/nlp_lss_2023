{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-brown",
   "metadata": {
    "id": "present-brown"
   },
   "source": [
    "# HW06: Transformers and Doc Embeddings\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d94f0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.matrix([[1, 2], [3, 4]])\n",
    "#np.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-ending",
   "metadata": {
    "id": "irish-ending",
    "outputId": "ed437d6f-ded0-4840-cfc1-d7e0b676527f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7946</th>\n",
       "      <td>sport</td>\n",
       "      <td>Ex-Hornets Executive Sentenced for Fraud (AP)</td>\n",
       "      <td>AP - Spencer Stolpen, former president of the ...</td>\n",
       "      <td>Ex-Hornets Executive Sentenced for Fraud (AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98024</th>\n",
       "      <td>sport</td>\n",
       "      <td>England: Balckburn still in last</td>\n",
       "      <td>Blackburn recovered from 3-1 down to draw 3-3 ...</td>\n",
       "      <td>England: Balckburn still in last Blackburn rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44953</th>\n",
       "      <td>business</td>\n",
       "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
       "      <td>Microsoft Corp., the world #39;s largest softw...</td>\n",
       "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81547</th>\n",
       "      <td>world</td>\n",
       "      <td>Seoul worried about Bush #39;s N. Korea stance</td>\n",
       "      <td>South Korean officials were very cautious when...</td>\n",
       "      <td>Seoul worried about Bush #39;s N. Korea stance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23020</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar Supported by Dip in Jobless Claims</td>\n",
       "      <td>CHICAGO (Reuters) - The dollar posted mild ga...</td>\n",
       "      <td>Dollar Supported by Dip in Jobless Claims  CHI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                              title  \\\n",
       "7946      sport      Ex-Hornets Executive Sentenced for Fraud (AP)   \n",
       "98024     sport                   England: Balckburn still in last   \n",
       "44953  business  Microsoft Asks EU Court to Suspend Antitrust R...   \n",
       "81547     world     Seoul worried about Bush #39;s N. Korea stance   \n",
       "23020  business          Dollar Supported by Dip in Jobless Claims   \n",
       "\n",
       "                                                    lead  \\\n",
       "7946   AP - Spencer Stolpen, former president of the ...   \n",
       "98024  Blackburn recovered from 3-1 down to draw 3-3 ...   \n",
       "44953  Microsoft Corp., the world #39;s largest softw...   \n",
       "81547  South Korean officials were very cautious when...   \n",
       "23020   CHICAGO (Reuters) - The dollar posted mild ga...   \n",
       "\n",
       "                                                    text  \n",
       "7946   Ex-Hornets Executive Sentenced for Fraud (AP) ...  \n",
       "98024  England: Balckburn still in last Blackburn rec...  \n",
       "44953  Microsoft Asks EU Court to Suspend Antitrust R...  \n",
       "81547  Seoul worried about Bush #39;s N. Korea stance...  \n",
       "23020  Dollar Supported by Dip in Jobless Claims  CHI...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-klein",
   "metadata": {
    "id": "regulated-klein"
   },
   "source": [
    "## Hugginface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-graph",
   "metadata": {
    "id": "reasonable-graph",
    "outputId": "91af619c-869d-40c0-c8c7-013453b6a022"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
    "import troch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-village",
   "metadata": {
    "id": "confident-village"
   },
   "outputs": [],
   "source": [
    "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-object",
   "metadata": {
    "id": "psychological-object"
   },
   "outputs": [],
   "source": [
    "##TODO print the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-recommendation",
   "metadata": {
    "id": "statistical-recommendation"
   },
   "outputs": [],
   "source": [
    "##TODO split the sample into a training and a test set \n",
    "##TODO prepare the dataset for torch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-compound",
   "metadata": {
    "id": "piano-compound"
   },
   "outputs": [],
   "source": [
    "##TODO fit the model and print the obtained accuracy (hint: you can follow the training steps in the notebook. To learn more, checkout the trainer class of huggingface transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe3a17",
   "metadata": {
    "id": "e7fe3a17"
   },
   "source": [
    "# Doc Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41f71c",
   "metadata": {
    "id": "3b41f71c"
   },
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "!unzip sts2017.eval.v1.1.zip \n",
    "!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a11ab",
   "metadata": {
    "id": "d48a11ab"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8bcb4",
   "metadata": {
    "id": "dee8bcb4"
   },
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f02f97",
   "metadata": {
    "id": "46f02f97"
   },
   "outputs": [],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965242a5",
   "metadata": {
    "id": "965242a5"
   },
   "outputs": [],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset\n",
    "##TODO derive the word vectors for each text in the dataset\n",
    "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
    "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b67c8",
   "metadata": {
    "id": "e67b67c8"
   },
   "outputs": [],
   "source": [
    "##TODO do the same with embeddings provided by spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf40ced",
   "metadata": {
    "id": "2cf40ced"
   },
   "outputs": [],
   "source": [
    "##TODO do the same with SBERT embeddings"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
