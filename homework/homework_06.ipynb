{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "present-brown",
      "metadata": {
        "id": "present-brown"
      },
      "source": [
        "# HW06: Transformers and Doc Embeddings\n",
        "\n",
        "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "irish-ending",
      "metadata": {
        "id": "irish-ending",
        "outputId": "ed437d6f-ded0-4840-cfc1-d7e0b676527f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7946</th>\n",
              "      <td>sport</td>\n",
              "      <td>Ex-Hornets Executive Sentenced for Fraud (AP)</td>\n",
              "      <td>AP - Spencer Stolpen, former president of the ...</td>\n",
              "      <td>Ex-Hornets Executive Sentenced for Fraud (AP) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98024</th>\n",
              "      <td>sport</td>\n",
              "      <td>England: Balckburn still in last</td>\n",
              "      <td>Blackburn recovered from 3-1 down to draw 3-3 ...</td>\n",
              "      <td>England: Balckburn still in last Blackburn rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44953</th>\n",
              "      <td>business</td>\n",
              "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
              "      <td>Microsoft Corp., the world #39;s largest softw...</td>\n",
              "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81547</th>\n",
              "      <td>world</td>\n",
              "      <td>Seoul worried about Bush #39;s N. Korea stance</td>\n",
              "      <td>South Korean officials were very cautious when...</td>\n",
              "      <td>Seoul worried about Bush #39;s N. Korea stance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23020</th>\n",
              "      <td>business</td>\n",
              "      <td>Dollar Supported by Dip in Jobless Claims</td>\n",
              "      <td>CHICAGO (Reuters) - The dollar posted mild ga...</td>\n",
              "      <td>Dollar Supported by Dip in Jobless Claims  CHI...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          label                                              title  \\\n",
              "7946      sport      Ex-Hornets Executive Sentenced for Fraud (AP)   \n",
              "98024     sport                   England: Balckburn still in last   \n",
              "44953  business  Microsoft Asks EU Court to Suspend Antitrust R...   \n",
              "81547     world     Seoul worried about Bush #39;s N. Korea stance   \n",
              "23020  business          Dollar Supported by Dip in Jobless Claims   \n",
              "\n",
              "                                                    lead  \\\n",
              "7946   AP - Spencer Stolpen, former president of the ...   \n",
              "98024  Blackburn recovered from 3-1 down to draw 3-3 ...   \n",
              "44953  Microsoft Corp., the world #39;s largest softw...   \n",
              "81547  South Korean officials were very cautious when...   \n",
              "23020   CHICAGO (Reuters) - The dollar posted mild ga...   \n",
              "\n",
              "                                                    text  \n",
              "7946   Ex-Hornets Executive Sentenced for Fraud (AP) ...  \n",
              "98024  England: Balckburn still in last Blackburn rec...  \n",
              "44953  Microsoft Asks EU Court to Suspend Antitrust R...  \n",
              "81547  Seoul worried about Bush #39;s N. Korea stance...  \n",
              "23020  Dollar Supported by Dip in Jobless Claims  CHI...  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df = df.sample(n=10000) # # only use 10K datapoints\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regulated-klein",
      "metadata": {
        "id": "regulated-klein"
      },
      "source": [
        "## Hugginface Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reasonable-graph",
      "metadata": {
        "id": "reasonable-graph",
        "outputId": "91af619c-869d-40c0-c8c7-013453b6a022"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
        "import troch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "confident-village",
      "metadata": {
        "id": "confident-village"
      },
      "outputs": [],
      "source": [
        "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "psychological-object",
      "metadata": {
        "id": "psychological-object"
      },
      "outputs": [],
      "source": [
        "##TODO print the summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statistical-recommendation",
      "metadata": {
        "id": "statistical-recommendation"
      },
      "outputs": [],
      "source": [
        "##TODO split the sample into a training and a test set \n",
        "##TODO prepare the dataset for torch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piano-compound",
      "metadata": {
        "id": "piano-compound"
      },
      "outputs": [],
      "source": [
        "##TODO fit the model and print the obtained accuracy (hint: you can follow the training steps in the notebook. To learn more, checkout the trainer class of huggingface transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fe3a17",
      "metadata": {
        "id": "e7fe3a17"
      },
      "source": [
        "# Doc Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b41f71c",
      "metadata": {
        "id": "3b41f71c"
      },
      "outputs": [],
      "source": [
        "# obtain the data\n",
        "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
        "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
        "\n",
        "!unzip sts2017.eval.v1.1.zip \n",
        "!unzip sts2017.gs.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48a11ab",
      "metadata": {
        "id": "d48a11ab"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "\n",
        "def load_STS_data():\n",
        "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
        "        labels = [float(line.strip()) for line in f]\n",
        "    \n",
        "    text_a, text_b = [], []\n",
        "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(\"\\t\")\n",
        "            text_a.append(line[0])\n",
        "            text_b.append(line[1])\n",
        "    return text_a, text_b, labels\n",
        "\n",
        "text_a, text_b, labels = load_STS_data()\n",
        "text_a[0], text_b[0], labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee8bcb4",
      "metadata": {
        "id": "dee8bcb4"
      },
      "outputs": [],
      "source": [
        "# some utils\n",
        "from scipy.stats import spearmanr\n",
        "def evaluate(predictions, labels):\n",
        "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_similarity(a,b):\n",
        "    return dot(a, b)/(norm(a)*norm(b))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f02f97",
      "metadata": {
        "id": "46f02f97"
      },
      "outputs": [],
      "source": [
        "# Wordcounts baseline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "vec.fit(text_a + text_b)\n",
        "\n",
        "# encode documents\n",
        "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
        "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
        "\n",
        "# predict cosine similarities\n",
        "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
        "\n",
        "# evaluate\n",
        "evaluate(predictions, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965242a5",
      "metadata": {
        "id": "965242a5"
      },
      "outputs": [],
      "source": [
        "##TODO train Doc2Vec on the texts in the dataset\n",
        "##TODO derive the word vectors for each text in the dataset\n",
        "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
        "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67b67c8",
      "metadata": {
        "id": "e67b67c8"
      },
      "outputs": [],
      "source": [
        "##TODO do the same with embeddings provided by spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf40ced",
      "metadata": {
        "id": "2cf40ced"
      },
      "outputs": [],
      "source": [
        "##TODO do the same with SBERT embeddings"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}