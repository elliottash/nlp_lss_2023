{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-brown",
   "metadata": {},
   "source": [
    "# HW09: Transformers\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7946</th>\n",
       "      <td>sport</td>\n",
       "      <td>Ex-Hornets Executive Sentenced for Fraud (AP)</td>\n",
       "      <td>AP - Spencer Stolpen, former president of the ...</td>\n",
       "      <td>Ex-Hornets Executive Sentenced for Fraud (AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98024</th>\n",
       "      <td>sport</td>\n",
       "      <td>England: Balckburn still in last</td>\n",
       "      <td>Blackburn recovered from 3-1 down to draw 3-3 ...</td>\n",
       "      <td>England: Balckburn still in last Blackburn rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44953</th>\n",
       "      <td>business</td>\n",
       "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
       "      <td>Microsoft Corp., the world #39;s largest softw...</td>\n",
       "      <td>Microsoft Asks EU Court to Suspend Antitrust R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81547</th>\n",
       "      <td>world</td>\n",
       "      <td>Seoul worried about Bush #39;s N. Korea stance</td>\n",
       "      <td>South Korean officials were very cautious when...</td>\n",
       "      <td>Seoul worried about Bush #39;s N. Korea stance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23020</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar Supported by Dip in Jobless Claims</td>\n",
       "      <td>CHICAGO (Reuters) - The dollar posted mild ga...</td>\n",
       "      <td>Dollar Supported by Dip in Jobless Claims  CHI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                              title  \\\n",
       "7946      sport      Ex-Hornets Executive Sentenced for Fraud (AP)   \n",
       "98024     sport                   England: Balckburn still in last   \n",
       "44953  business  Microsoft Asks EU Court to Suspend Antitrust R...   \n",
       "81547     world     Seoul worried about Bush #39;s N. Korea stance   \n",
       "23020  business          Dollar Supported by Dip in Jobless Claims   \n",
       "\n",
       "                                                    lead  \\\n",
       "7946   AP - Spencer Stolpen, former president of the ...   \n",
       "98024  Blackburn recovered from 3-1 down to draw 3-3 ...   \n",
       "44953  Microsoft Corp., the world #39;s largest softw...   \n",
       "81547  South Korean officials were very cautious when...   \n",
       "23020   CHICAGO (Reuters) - The dollar posted mild ga...   \n",
       "\n",
       "                                                    text  \n",
       "7946   Ex-Hornets Executive Sentenced for Fraud (AP) ...  \n",
       "98024  England: Balckburn still in last Blackburn rec...  \n",
       "44953  Microsoft Asks EU Court to Suspend Antitrust R...  \n",
       "81547  Seoul worried about Bush #39;s N. Korea stance...  \n",
       "23020  Dollar Supported by Dip in Jobless Claims  CHI...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-klein",
   "metadata": {},
   "source": [
    "## Hugginface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reasonable-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = 4\n",
    "transformer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confident-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO print the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-packet",
   "metadata": {},
   "source": [
    "**Hint:** All the vectorized pieces of text must have the same length (which will be equal to the input size). You have two options to ensure this:\n",
    "\n",
    "1. Set the maximum length equal to the length of the shortest vectorized text\n",
    "2. Choose the maximum length and then exclude all the data points that have vectors shorter than that length\n",
    "\n",
    "**Hint:** Tensorflow requires your labels to be integers, not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statistical-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO split the sample into a training and a test set \n",
    "##TODO prepare the dataset for tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO fit the model and print the obtained accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe3a17",
   "metadata": {},
   "source": [
    "# LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "##TODO create a sequential model with an embedding layer, a LSTM layer and two hidden layers with ReLu activation function, followed by dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3560a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO compile the model and fit it to predict the business label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
