{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21e1ead",
   "metadata": {
    "id": "d21e1ead"
   },
   "source": [
    "# HW04: ML and DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d1f0b",
   "metadata": {
    "id": "680d1f0b"
   },
   "source": [
    "Remember that these homework work as a completion grade. **You can skip one section without losing credit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf38c8",
   "metadata": {
    "id": "c9bf38c8"
   },
   "source": [
    "## Load and Pre-process Text\n",
    "We do sentiment analysis on the [Movie Review Data](https://www.cs.cornell.edu/people/pabo/movie-review-data/). If you would like to know more about the data, have a look at [the paper](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.pdf) (but no need to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21439804",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21439804",
    "outputId": "a30baf4d-a3c9-4ccb-b667-7991ae9a5c84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-23 10:50:26--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4029756 (3.8M) [application/x-gzip]\n",
      "Saving to: 'scale_data.tar.gz'\n",
      "\n",
      "scale_data.tar.gz   100%[===================>]   3.84M  3.90MB/s    in 1.0s    \n",
      "\n",
      "2023-03-23 10:50:28 (3.90 MB/s) - 'scale_data.tar.gz' saved [4029756/4029756]\n",
      "\n",
      "--2023-03-23 10:50:28--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8853204 (8.4M) [application/x-gzip]\n",
      "Saving to: 'scale_whole_review.tar.gz'\n",
      "\n",
      "scale_whole_review. 100%[===================>]   8.44M  2.35MB/s    in 3.6s    \n",
      "\n",
      "2023-03-23 10:50:32 (2.35 MB/s) - 'scale_whole_review.tar.gz' saved [8853204/8853204]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this tutorial, we do sentiment analysis\n",
    "# download the data\n",
    "#!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar xf aclImdb_v1.tar.gz\n",
    "\n",
    "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
    "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
    " \n",
    "!tar xf scale_data.tar.gz \n",
    "!tar xf scale_whole_review.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685ef2e",
   "metadata": {
    "id": "d685ef2e"
   },
   "source": [
    "First, we have to load the data for which we provide the function below. Note how we also preprocess the text using gensim's simple_preprocess() function and how we already split the data into a train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18a238d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a18a238d",
    "outputId": "39b85e2c-668f-47d4-f332-6edfe679a0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: bloody child the director writer cinematographer nina menkes screenwriter tinka menkes editors nina and tina menkes cast tinka menkes captain sherry sibley murdered wife robert mueller murderer russ little sergeant jack hara enlisted man runtime mirage reviewed by dennis schwartz an amazingly strange film confusing and not thoroughly enjoyable but film found more interesting than thought possible at first viewing this experimental film in minimalist story telling film consisting of disturbing visualizations and almost no dialogue had concept that was greater than how the film turned out it felt at times like was watching paint dry on the wall but the reward for sitting through those excruciatingly redundant scenes was in seeing something different something that cast spell of sorcery over terrible incident as believe the film in its unique and sometimes shrill voice does justice in commenting on the violence in american society especially against women the film uses its impressions of the marine base as metaphor for the social violence in today american society and to give it its startling look of reality marines were used as the actors it was filmed at twenty nine palms calif the largest marine base in the country which is located in the mojave desert the plot is simple it is about real incident that happened to marine returning from the persian gulf war who murdered his wife and was caught at sunrise digging her grave in the mojave desert by military patrol the film tells its story by showing the military police by the murder site making small talk while awaiting for the arrest to be completed and the marines off base relaxing in country and western lounge as some marines lewdly dance in front of some female patrons the film boredom is broken up by camera shots of marines in conversations that we can hear in its entirety but are treated to little snippets of hearing mostly their curse words the captain in charge of the arrest is tinka menkes the director sister she tries to get the male marines to take this incident seriously and act professional as they treat her as an outsider but with proper military respect because the film had no linear story and followed no chronological order and it stressed the mundaneness of life on the base and did not film its story in the usual way murder investigation is filmed it appeared surreal for whatever reason nina menkes the great sadness of zohara magdalena viraga queen of diamonds director am not familiar with has chosen to put parts of macbeth into the film the disembodied voice of the murdered wife is heard at times as the voice of violated spirit along with scenes from northeast africa tinka is sitting naked in the forest clearing writing unreadable words on her arm there is also riderless black horse going on the base and the film ends on quote from the book of genesis about lot wife turned into pillar of salt when she looked back thought these additions seemed to serve mostly as unneeded arty pretext the arrested marine is not seen in total but is viewed from side glances of him in the same car as his bloodied dead wife military policeman is seen shoving the marine face into his dead wife bloody lap and yelling some nearly inaudible obscenities at him the film tells nothing about the why and how of the murder but touches on the reality of life on the marine base making it seem like wasteland inhabited only by those sent to purgatory the unsettling milieu in which the crime took place speaks volumes about why the murder might have taken place the film seems to be telling us that it up to us to make sense of what we ve seen though the film was dull and did not move me while was watching it it did something to me afterwards intellectually it made me think of military base the persian gulf war and of marital abuse but it made me think of them without the usual concepts bring to my thinking cap does that make this great film no but it makes it an interesting one film that can easily dismiss its filming of the arrest is so chilling and memorable because what is so dull and ordinary about the crime scene is the understated reason for the origin of the violence contrary to the way hollywood films portray violence here it is part of the landscape that one regularly sees but perhaps one doesn really understand or want to understand what evil society has created reviewed on dennis schwartz ozus world movie reviews all rights reserved dennis schwartz \n",
      "label: 0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "def load_data():\n",
    "    examples, labels = [], []\n",
    "    authors = os.listdir(\"scale_whole_review\")\n",
    "    for author in authors:\n",
    "        path = os.listdir(os.path.join(\"scale_whole_review\", author, \"txt.parag\"))\n",
    "        fn_ids = os.path.join(\"scaledata\", author, \"id.\" + author)\n",
    "        fn_ratings = os.path.join(\"scaledata\", author, \"rating.\" + author)\n",
    "        with open(fn_ids) as ids, open(fn_ratings) as ratings:\n",
    "            for idx, rating in zip(ids, ratings):\n",
    "                labels.append(float(rating.strip()))\n",
    "                filename_text = os.path.join(\"scale_whole_review\", author, \"txt.parag\", idx.strip() + \".txt\")\n",
    "                with open(filename_text, encoding='latin-1') as f:\n",
    "                    examples.append(\" \".join(simple_preprocess(f.read())))\n",
    "    return examples, labels\n",
    "                  \n",
    "X,y  = load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print (\"text:\", X_train[0], \"\\nlabel:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "582e386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5836076326774001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284033cf",
   "metadata": {
    "id": "284033cf"
   },
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09aff185",
   "metadata": {
    "id": "09aff185"
   },
   "outputs": [],
   "source": [
    "# train a TF_IDF Vectorizer on X_train and vectorize X_train and X_test\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(min_df=0.01, # at min 1% of docs\n",
    "                        max_df=.5,  \n",
    "                        stop_words='english',\n",
    "                        ngram_range=(1,2))\n",
    "\n",
    "##TODO train vectorizer\n",
    "\n",
    "##TODO transform X_train to TF-IDF values\n",
    "X_train_tfidf = vec.fit_transform(X_train)\n",
    "X_train_feature_names = vec.get_feature_names_out()\n",
    "##TODO transform X_test to TF-IDF values\n",
    "X_test_tfidf = vec.fit_transform(X_test)\n",
    "X_test_feature_names = vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15607667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# get indixes for the train and test data \n",
    "X_train_index = np.nonzero(np.in1d(X_train_feature_names, X_test_feature_names))[0]\n",
    "X_test_index = np.nonzero(np.in1d(X_test_feature_names, X_train_feature_names))[0]\n",
    "\n",
    "print(len(X_train_index) == len(X_test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d44dbb",
   "metadata": {
    "id": "58d44dbb"
   },
   "outputs": [],
   "source": [
    "##TODO scale both training and test data with the standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf_scaled = scaler.fit_transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb9f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3354, 5593) (1652, 5687)\n",
      "['aaron' 'abandon' 'abandoned' ... 'youngster' 'youngsters' 'youth']\n",
      "['aaron' 'abandon' 'abandoned' ... 'youthful' 'zero' 'zone']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_tfidf_scaled.shape, X_test_tfidf_scaled.shape)\n",
    "print(X_train_feature_names)\n",
    "print(X_test_feature_names)\n",
    "X_train_tfidf_scaled.toarray()\n",
    "#matrix of all names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d8a57",
   "metadata": {
    "id": "ad9d8a57"
   },
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5f4520",
   "metadata": {
    "id": "1e5f4520"
   },
   "outputs": [],
   "source": [
    "##TODO train an elastic net on the transformed output of the scaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "en = ElasticNet(alpha=0.01)\n",
    "\n",
    "#get right dimensions\n",
    "X_train_d = X_train_tfidf_scaled[:, X_train_index]\n",
    "X_test_d = X_test_tfidf_scaled[:, X_test_index]\n",
    "\n",
    "##TODO train the ElasticNet\n",
    "en.fit(X_train_d ,y_train)\n",
    "\n",
    "##TODO predict the testset\n",
    "y_pred = en.predict(X_test_d)\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b073228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.4934699420124996\n",
      "Mean Squared error:  0.016675995953272474\n"
     ]
    }
   ],
   "source": [
    "##TODO print mean squared error and r2 score on the test set\n",
    "print('R^2: ', r2_score(y_test,y_pred))\n",
    "#print('Accuracy Score: ',accuracy_score(y_test,y_pred))\n",
    "print('Mean Squared error: ', mean_squared_error(y_test,y_pred))\n",
    "#print('Balanced Accuracy score: ', balanced_accuracy_score(y_test,y_pred))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d1ef8",
   "metadata": {
    "id": "872d1ef8"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2756e",
   "metadata": {
    "id": "27e2756e"
   },
   "source": [
    "Next, we train an OLS model doing binary prediction on these movie reviews. Two get two bins, we transform the continuous ratings into two classes, where one class contains all the negative ratings (value < 0.5), the other class all the positive ratings (value > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cbd752c",
   "metadata": {
    "id": "9cbd752c"
   },
   "outputs": [],
   "source": [
    "y_train = [1 if i >= 0.5 else 0 for i in y_train]\n",
    "y_test = [1 if i >= 0.5 else 0 for i in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2c239d",
   "metadata": {
    "id": "2c2c239d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.799636803874092\n",
      "Balanced Accuracy score:  0.716512901290129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sorenlambrecht/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "##TODO train logistic regression on X_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "##TODO train a logistic regression\n",
    "clf = logistic_regression.fit(X_train_d, y_train)\n",
    "##TODO predict the testset \n",
    "y_pred_2 = clf.predict(X_test_d)\n",
    "##since we have continuous output, we need to post-process our labels into two classes. We choose a threshold of 0.5 \n",
    "def map_predictions(predicted):\n",
    "    predicted = [1 if i > 0.5 else 0 for i in predicted]\n",
    "    return predicted\n",
    "\n",
    "##TODO print the accuracy of our classifier on the testset\n",
    "print('Accuracy Score: ',accuracy_score(y_test,map_predictions(y_pred_2)))\n",
    "print('Balanced Accuracy score: ', balanced_accuracy_score(y_test, map_predictions(y_pred_2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6d0c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thrillers', 'thrilling', 'thrills', 'throw', 'throwing', 'thrown',\n",
       "       'throws', 'thumbs', 'ticket'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO print the 10 most informative words of the regression (the 10 words having the highest coefficients)\n",
    "coeff1 = clf.coef_[0]\n",
    "coeff = clf.coef_[0]\n",
    "coeff.sort()\n",
    "imp_coeff = coeff[-9:]\n",
    "word_index = np.nonzero(np.in1d(coeff1, imp_coeff))[0]\n",
    "X_train_feature_names[word_index]\n",
    "\n",
    "#weird result but coef_ are not supposed to be ordered..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3hNKx6fUGgCL",
   "metadata": {
    "id": "3hNKx6fUGgCL"
   },
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6bc62",
   "metadata": {
    "id": "d0a6bc62"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ueplJsWuS_zl",
   "metadata": {
    "id": "ueplJsWuS_zl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-23 10:51:05--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29470338 (28M) [text/plain]\n",
      "Saving to: 'train.csv'\n",
      "\n",
      "train.csv           100%[===================>]  28.10M  4.43MB/s    in 7.1s    \n",
      "\n",
      "2023-03-23 10:51:13 (3.96 MB/s) - 'train.csv' saved [29470338/29470338]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17379</th>\n",
       "      <td>world</td>\n",
       "      <td>Australian high court limits unions' right to ...</td>\n",
       "      <td>AFP - Australian Prime Minister John Howard ha...</td>\n",
       "      <td>Australian high court limits unions' right to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25976</th>\n",
       "      <td>sport</td>\n",
       "      <td>Echoes Across Forty Years</td>\n",
       "      <td>On a day when the Browns last championship tea...</td>\n",
       "      <td>Echoes Across Forty Years On a day when the Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71699</th>\n",
       "      <td>business</td>\n",
       "      <td>Mittal Family Forges \\$17.8 Bln Steel Deal</td>\n",
       "      <td>AMSTERDAM (Reuters) - Lakshmi Mittal, one of ...</td>\n",
       "      <td>Mittal Family Forges \\$17.8 Bln Steel Deal  AM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48920</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>PalmOne unveils 256MB Flash drive T5 PDA</td>\n",
       "      <td>PalmOne launched the Tungsten T5, its first PD...</td>\n",
       "      <td>PalmOne unveils 256MB Flash drive T5 PDA PalmO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51450</th>\n",
       "      <td>business</td>\n",
       "      <td>China to 'phase out' measures aimed at cooling...</td>\n",
       "      <td>AFP - China will phase out measures aimed at r...</td>\n",
       "      <td>China to 'phase out' measures aimed at cooling...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                              title  \\\n",
       "17379     world  Australian high court limits unions' right to ...   \n",
       "25976     sport                          Echoes Across Forty Years   \n",
       "71699  business         Mittal Family Forges \\$17.8 Bln Steel Deal   \n",
       "48920  sci/tech           PalmOne unveils 256MB Flash drive T5 PDA   \n",
       "51450  business  China to 'phase out' measures aimed at cooling...   \n",
       "\n",
       "                                                    lead  \\\n",
       "17379  AFP - Australian Prime Minister John Howard ha...   \n",
       "25976  On a day when the Browns last championship tea...   \n",
       "71699   AMSTERDAM (Reuters) - Lakshmi Mittal, one of ...   \n",
       "48920  PalmOne launched the Tungsten T5, its first PD...   \n",
       "51450  AFP - China will phase out measures aimed at r...   \n",
       "\n",
       "                                                    text  \n",
       "17379  Australian high court limits unions' right to ...  \n",
       "25976  Echoes Across Forty Years On a day when the Br...  \n",
       "71699  Mittal Family Forges \\$17.8 Bln Steel Deal  AM...  \n",
       "48920  PalmOne unveils 256MB Flash drive T5 PDA PalmO...  \n",
       "51450  China to 'phase out' measures aimed at cooling...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the AG news dataset (same as hw01)\n",
    "#Download them from here \n",
    "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6ZVZfDTBwH",
   "metadata": {
    "id": "df6ZVZfDTBwH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17379    0\n",
       "25976    0\n",
       "71699    1\n",
       "48920    0\n",
       "51450    1\n",
       "Name: business, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new variable \"business\" that takes value 1 if the label is business and 0 otherwise\n",
    "df['business'] = df['label'].apply(lambda x: int(x=='business'))\n",
    "y = df['business'].values\n",
    "df['business'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7CFbsYDMTCTt",
   "metadata": {
    "id": "7CFbsYDMTCTt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "      <th>business</th>\n",
       "      <th>tokens</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17379</th>\n",
       "      <td>world</td>\n",
       "      <td>Australian high court limits unions' right to ...</td>\n",
       "      <td>AFP - Australian Prime Minister John Howard ha...</td>\n",
       "      <td>Australian high court limits unions' right to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[australian, high, court, limit, union, right,...</td>\n",
       "      <td>australian high court limit union right strike...</td>\n",
       "      <td>a u s t r a l i a n   h i g h   c o u r t   l ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25976</th>\n",
       "      <td>sport</td>\n",
       "      <td>Echoes Across Forty Years</td>\n",
       "      <td>On a day when the Browns last championship tea...</td>\n",
       "      <td>Echoes Across Forty Years On a day when the Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>[echo, year, day, browns, championship, team, ...</td>\n",
       "      <td>echo year day browns championship team salute ...</td>\n",
       "      <td>e c h o   y e a r   d a y   b r o w n s   c h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71699</th>\n",
       "      <td>business</td>\n",
       "      <td>Mittal Family Forges \\$17.8 Bln Steel Deal</td>\n",
       "      <td>AMSTERDAM (Reuters) - Lakshmi Mittal, one of ...</td>\n",
       "      <td>Mittal Family Forges \\$17.8 Bln Steel Deal  AM...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mittal, family, forges, \\$17.8, bln, steel, d...</td>\n",
       "      <td>mittal family forges \\$17.8 bln steel deal   a...</td>\n",
       "      <td>m i t t a l   f a m i l y   f o r g e s   \\ $ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48920</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>PalmOne unveils 256MB Flash drive T5 PDA</td>\n",
       "      <td>PalmOne launched the Tungsten T5, its first PD...</td>\n",
       "      <td>PalmOne unveils 256MB Flash drive T5 PDA PalmO...</td>\n",
       "      <td>0</td>\n",
       "      <td>[palmone, unveil, mb, flash, drive, t5, pda, p...</td>\n",
       "      <td>palmone unveil mb flash drive t5 pda palmone l...</td>\n",
       "      <td>p a l m o n e   u n v e i l   m b   f l a s h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51450</th>\n",
       "      <td>business</td>\n",
       "      <td>China to 'phase out' measures aimed at cooling...</td>\n",
       "      <td>AFP - China will phase out measures aimed at r...</td>\n",
       "      <td>China to 'phase out' measures aimed at cooling...</td>\n",
       "      <td>1</td>\n",
       "      <td>[china, phase, measure, aim, cool, economy, af...</td>\n",
       "      <td>china phase measure aim cool economy afp afp c...</td>\n",
       "      <td>c h i n a   p h a s e   m e a s u r e   a i m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36338</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Immersion Wins Patent Case Against Sony (AP)</td>\n",
       "      <td>AP - Immersion Corp., a small firm that develo...</td>\n",
       "      <td>Immersion Wins Patent Case Against Sony (AP) A...</td>\n",
       "      <td>0</td>\n",
       "      <td>[immersion, win, patent, case, sony, ap, ap, i...</td>\n",
       "      <td>immersion win patent case sony ap ap immersion...</td>\n",
       "      <td>i m m e r s i o n   w i n   p a t e n t   c a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>sport</td>\n",
       "      <td>Play-off earns Singh seventh victory of year</td>\n",
       "      <td>NOW that he is No1 in the world, Vijay Singh c...</td>\n",
       "      <td>Play-off earns Singh seventh victory of year N...</td>\n",
       "      <td>0</td>\n",
       "      <td>[play, earn, singh, seventh, victory, year, no...</td>\n",
       "      <td>play earn singh seventh victory year no1 world...</td>\n",
       "      <td>p l a y   e a r n   s i n g h   s e v e n t h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>sport</td>\n",
       "      <td>Hamm Goes for More Gold Amid Controversy</td>\n",
       "      <td>Despite the controversy surrounding his gold m...</td>\n",
       "      <td>Hamm Goes for More Gold Amid Controversy Despi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hamm, go, gold, amid, controversy, despite, c...</td>\n",
       "      <td>hamm go gold amid controversy despite controve...</td>\n",
       "      <td>h a m m   g o   g o l d   a m i d   c o n t r ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>business</td>\n",
       "      <td>Symantec Buys Security Consulting Pioneer stake</td>\n",
       "      <td>Symantec Corp. on Thursday announced that is a...</td>\n",
       "      <td>Symantec Buys Security Consulting Pioneer stak...</td>\n",
       "      <td>1</td>\n",
       "      <td>[symantec, buy, security, consulting, pioneer,...</td>\n",
       "      <td>symantec buy security consulting pioneer stake...</td>\n",
       "      <td>s y m a n t e c   b u y   s e c u r i t y   c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36875</th>\n",
       "      <td>sport</td>\n",
       "      <td>Sav Misses England Clash</td>\n",
       "      <td>Robbie Savage will miss Wales #39; 2006 World ...</td>\n",
       "      <td>Sav Misses England Clash Robbie Savage will mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sav, misses, england, clash, robbie, savage, ...</td>\n",
       "      <td>sav misses england clash robbie savage miss wa...</td>\n",
       "      <td>s a v   m i s s e s   e n g l a n d   c l a s ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                              title  \\\n",
       "17379     world  Australian high court limits unions' right to ...   \n",
       "25976     sport                          Echoes Across Forty Years   \n",
       "71699  business         Mittal Family Forges \\$17.8 Bln Steel Deal   \n",
       "48920  sci/tech           PalmOne unveils 256MB Flash drive T5 PDA   \n",
       "51450  business  China to 'phase out' measures aimed at cooling...   \n",
       "...         ...                                                ...   \n",
       "36338  sci/tech       Immersion Wins Patent Case Against Sony (AP)   \n",
       "26396     sport       Play-off earns Singh seventh victory of year   \n",
       "6454      sport           Hamm Goes for More Gold Amid Controversy   \n",
       "30223  business    Symantec Buys Security Consulting Pioneer stake   \n",
       "36875     sport                           Sav Misses England Clash   \n",
       "\n",
       "                                                    lead  \\\n",
       "17379  AFP - Australian Prime Minister John Howard ha...   \n",
       "25976  On a day when the Browns last championship tea...   \n",
       "71699   AMSTERDAM (Reuters) - Lakshmi Mittal, one of ...   \n",
       "48920  PalmOne launched the Tungsten T5, its first PD...   \n",
       "51450  AFP - China will phase out measures aimed at r...   \n",
       "...                                                  ...   \n",
       "36338  AP - Immersion Corp., a small firm that develo...   \n",
       "26396  NOW that he is No1 in the world, Vijay Singh c...   \n",
       "6454   Despite the controversy surrounding his gold m...   \n",
       "30223  Symantec Corp. on Thursday announced that is a...   \n",
       "36875  Robbie Savage will miss Wales #39; 2006 World ...   \n",
       "\n",
       "                                                    text  business  \\\n",
       "17379  Australian high court limits unions' right to ...         0   \n",
       "25976  Echoes Across Forty Years On a day when the Br...         0   \n",
       "71699  Mittal Family Forges \\$17.8 Bln Steel Deal  AM...         1   \n",
       "48920  PalmOne unveils 256MB Flash drive T5 PDA PalmO...         0   \n",
       "51450  China to 'phase out' measures aimed at cooling...         1   \n",
       "...                                                  ...       ...   \n",
       "36338  Immersion Wins Patent Case Against Sony (AP) A...         0   \n",
       "26396  Play-off earns Singh seventh victory of year N...         0   \n",
       "6454   Hamm Goes for More Gold Amid Controversy Despi...         0   \n",
       "30223  Symantec Buys Security Consulting Pioneer stak...         1   \n",
       "36875  Sav Misses England Clash Robbie Savage will mi...         0   \n",
       "\n",
       "                                                  tokens  \\\n",
       "17379  [australian, high, court, limit, union, right,...   \n",
       "25976  [echo, year, day, browns, championship, team, ...   \n",
       "71699  [mittal, family, forges, \\$17.8, bln, steel, d...   \n",
       "48920  [palmone, unveil, mb, flash, drive, t5, pda, p...   \n",
       "51450  [china, phase, measure, aim, cool, economy, af...   \n",
       "...                                                  ...   \n",
       "36338  [immersion, win, patent, case, sony, ap, ap, i...   \n",
       "26396  [play, earn, singh, seventh, victory, year, no...   \n",
       "6454   [hamm, go, gold, amid, controversy, despite, c...   \n",
       "30223  [symantec, buy, security, consulting, pioneer,...   \n",
       "36875  [sav, misses, england, clash, robbie, savage, ...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "17379  australian high court limit union right strike...   \n",
       "25976  echo year day browns championship team salute ...   \n",
       "71699  mittal family forges \\$17.8 bln steel deal   a...   \n",
       "48920  palmone unveil mb flash drive t5 pda palmone l...   \n",
       "51450  china phase measure aim cool economy afp afp c...   \n",
       "...                                                  ...   \n",
       "36338  immersion win patent case sony ap ap immersion...   \n",
       "26396  play earn singh seventh victory year no1 world...   \n",
       "6454   hamm go gold amid controversy despite controve...   \n",
       "30223  symantec buy security consulting pioneer stake...   \n",
       "36875  sav misses england clash robbie savage miss wa...   \n",
       "\n",
       "                                       preprocessed_text  \n",
       "17379  a u s t r a l i a n   h i g h   c o u r t   l ...  \n",
       "25976  e c h o   y e a r   d a y   b r o w n s   c h ...  \n",
       "71699  m i t t a l   f a m i l y   f o r g e s   \\ $ ...  \n",
       "48920  p a l m o n e   u n v e i l   m b   f l a s h ...  \n",
       "51450  c h i n a   p h a s e   m e a s u r e   a i m ...  \n",
       "...                                                  ...  \n",
       "36338  i m m e r s i o n   w i n   p a t e n t   c a ...  \n",
       "26396  p l a y   e a r n   s i n g h   s e v e n t h ...  \n",
       "6454   h a m m   g o   g o l d   a m i d   c o n t r ...  \n",
       "30223  s y m a n t e c   b u y   s e c u r i t y   c ...  \n",
       "36875  s a v   m i s s e s   e n g l a n d   c l a s ...  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# pre-process text as you did in HW02\n",
    "def tokenize(x):\n",
    "    return [w.lemma_.lower() for w in nlp(x) if not w.is_stop and not w.is_punct and not w.is_digit]\n",
    "df[\"tokens\"] = df[\"text\"].apply(lambda x: tokenize(x))\n",
    "df[\"preprocessed\"] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "df[\"preprocessed_text\"] = df[\"preprocessed\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a26c5476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO vectorize the pre-processed text using CountVectorizer\n",
    "corpus = df['preprocessed_text'].values\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "X_CV = vectorizer.fit_transform(corpus)\n",
    "X_CV = X_CV.toarray()\n",
    "#perhpas should do toarray() here...\n",
    "vectorizer.get_feature_names_out()\n",
    "X_CV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b731f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get classes by understanding labels\n",
    "# predicting only business so perhaps binary classifaction\n",
    "y_lables = df['business'].values\n",
    "#y_lables = y_lables.reshape(10000,1, 1)\n",
    "y_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e79db793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "#X_CV_train = X_CV.reshape(10000, 1, 54, 1)\n",
    "X_CV_train = np.expand_dims(X_CV, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaae877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sura ab out this..\n",
    "num_classes = 1\n",
    "input_shape = (55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a59b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000, 55, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_lables.shape)\n",
    "print(X_CV_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e66fc",
   "metadata": {
    "id": "9b6e66fc"
   },
   "source": [
    "Your goal here is to use features from the Vectorized text to predict whether the snippet is from a business article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b718ae5",
   "metadata": {
    "id": "0b718ae5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:54:06.945321: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                1792      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.7399 - val_loss: 0.0000e+00 - val_accuracy: 0.7450\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.7462 - val_loss: 0.0000e+00 - val_accuracy: 0.7450\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.7462 - val_loss: 0.0000e+00 - val_accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.7462 - val_loss: 0.0000e+00 - val_accuracy: 0.7450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97f6100400>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential, Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "## TODO build a MLP model with at least 2 hidden layers with ReLU activation, followed \n",
    "#by dropout and an output layer with sigmoid activation\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='sigmoid'),\n",
    "])\n",
    "## TODO compile the model\n",
    "print(model.summary())\n",
    "\n",
    "## TODO fit the model using early stopping to predict the business label\n",
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_CV_train, y_lables, batch_size=batch_size, epochs=epochs, validation_split=0.1,\n",
    "         callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5588f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not doing any predictions on other parts of the dataset but didnt seem to be part of the task\n",
    "#accuracy is relatvily low but could be imporved by changing the network\n",
    "#also, skipping last part since this took a little while and we're allowed to skip one part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958fddb",
   "metadata": {
    "id": "6958fddb"
   },
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64674cd4",
   "metadata": {
    "id": "64674cd4"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "##TODO build a simple autoencoder with two compression layers and two reconstruction layers using ReLu\n",
    "##TODO compile and fit the model minimizing \"mean_squared_error\"\n",
    "##report r_squared during training (the function r2 defined above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f767eee",
   "metadata": {
    "id": "6f767eee"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "##TODO compress the vectorized text (X.todense())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
