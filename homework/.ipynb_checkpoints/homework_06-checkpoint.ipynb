{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-brown",
   "metadata": {
    "id": "present-brown"
   },
   "source": [
    "# HW06: Transformers and Doc Embeddings\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-ending",
   "metadata": {
    "id": "irish-ending",
    "outputId": "ed437d6f-ded0-4840-cfc1-d7e0b676527f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-03 12:01:35--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29470338 (28M) [text/plain]\n",
      "Saving to: 'train.csv'\n",
      "\n",
      "train.csv           100%[===================>]  28.10M  4.92MB/s    in 6.3s    \n",
      "\n",
      "2023-04-03 12:01:45 (4.48 MB/s) - 'train.csv' saved [29470338/29470338]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52083</th>\n",
       "      <td>sport</td>\n",
       "      <td>Davenport Powers Past Molik, Dementieva Falls</td>\n",
       "      <td>FILDERSTADT, Germany (Reuters) - Lindsay Dave...</td>\n",
       "      <td>Davenport Powers Past Molik, Dementieva Falls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34647</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Apple iMac G5</td>\n",
       "      <td>1.8-GHz PowerPC G5 processor, 512MB DDR SDRAM,...</td>\n",
       "      <td>Apple iMac G5 1.8-GHz PowerPC G5 processor, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29757</th>\n",
       "      <td>world</td>\n",
       "      <td>A Beslan mother #39;s impossible choice</td>\n",
       "      <td>After more than 24 hours in captivity in Besla...</td>\n",
       "      <td>A Beslan mother #39;s impossible choice After ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112012</th>\n",
       "      <td>business</td>\n",
       "      <td>US mobile giants in merger talks</td>\n",
       "      <td>US mobile operators Sprint and Nextel are in t...</td>\n",
       "      <td>US mobile giants in merger talks US mobile ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98506</th>\n",
       "      <td>sport</td>\n",
       "      <td>Sorenstam Ends the Year With Trophy (AP)</td>\n",
       "      <td>AP - Despite 33 victories in the last four yea...</td>\n",
       "      <td>Sorenstam Ends the Year With Trophy (AP) AP - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                          title  \\\n",
       "52083      sport  Davenport Powers Past Molik, Dementieva Falls   \n",
       "34647   sci/tech                                  Apple iMac G5   \n",
       "29757      world        A Beslan mother #39;s impossible choice   \n",
       "112012  business               US mobile giants in merger talks   \n",
       "98506      sport       Sorenstam Ends the Year With Trophy (AP)   \n",
       "\n",
       "                                                     lead  \\\n",
       "52083    FILDERSTADT, Germany (Reuters) - Lindsay Dave...   \n",
       "34647   1.8-GHz PowerPC G5 processor, 512MB DDR SDRAM,...   \n",
       "29757   After more than 24 hours in captivity in Besla...   \n",
       "112012  US mobile operators Sprint and Nextel are in t...   \n",
       "98506   AP - Despite 33 victories in the last four yea...   \n",
       "\n",
       "                                                     text  \n",
       "52083   Davenport Powers Past Molik, Dementieva Falls ...  \n",
       "34647   Apple iMac G5 1.8-GHz PowerPC G5 processor, 51...  \n",
       "29757   A Beslan mother #39;s impossible choice After ...  \n",
       "112012  US mobile giants in merger talks US mobile ope...  \n",
       "98506   Sorenstam Ends the Year With Trophy (AP) AP - ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "    return label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-klein",
   "metadata": {
    "id": "regulated-klein"
   },
   "source": [
    "## Hugginface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813bb7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52083</th>\n",
       "      <td>sport</td>\n",
       "      <td>Davenport Powers Past Molik, Dementieva Falls</td>\n",
       "      <td>FILDERSTADT, Germany (Reuters) - Lindsay Dave...</td>\n",
       "      <td>Davenport Powers Past Molik, Dementieva Falls ...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34647</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Apple iMac G5</td>\n",
       "      <td>1.8-GHz PowerPC G5 processor, 512MB DDR SDRAM,...</td>\n",
       "      <td>Apple iMac G5 1.8-GHz PowerPC G5 processor, 51...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29757</th>\n",
       "      <td>world</td>\n",
       "      <td>A Beslan mother #39;s impossible choice</td>\n",
       "      <td>After more than 24 hours in captivity in Besla...</td>\n",
       "      <td>A Beslan mother #39;s impossible choice After ...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112012</th>\n",
       "      <td>business</td>\n",
       "      <td>US mobile giants in merger talks</td>\n",
       "      <td>US mobile operators Sprint and Nextel are in t...</td>\n",
       "      <td>US mobile giants in merger talks US mobile ope...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98506</th>\n",
       "      <td>sport</td>\n",
       "      <td>Sorenstam Ends the Year With Trophy (AP)</td>\n",
       "      <td>AP - Despite 33 victories in the last four yea...</td>\n",
       "      <td>Sorenstam Ends the Year With Trophy (AP) AP - ...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                          title  \\\n",
       "52083      sport  Davenport Powers Past Molik, Dementieva Falls   \n",
       "34647   sci/tech                                  Apple iMac G5   \n",
       "29757      world        A Beslan mother #39;s impossible choice   \n",
       "112012  business               US mobile giants in merger talks   \n",
       "98506      sport       Sorenstam Ends the Year With Trophy (AP)   \n",
       "\n",
       "                                                     lead  \\\n",
       "52083    FILDERSTADT, Germany (Reuters) - Lindsay Dave...   \n",
       "34647   1.8-GHz PowerPC G5 processor, 512MB DDR SDRAM,...   \n",
       "29757   After more than 24 hours in captivity in Besla...   \n",
       "112012  US mobile operators Sprint and Nextel are in t...   \n",
       "98506   AP - Despite 33 victories in the last four yea...   \n",
       "\n",
       "                                                     text        labels  \n",
       "52083   Davenport Powers Past Molik, Dementieva Falls ...  [0, 0, 1, 0]  \n",
       "34647   Apple iMac G5 1.8-GHz PowerPC G5 processor, 51...  [0, 1, 0, 0]  \n",
       "29757   A Beslan mother #39;s impossible choice After ...  [0, 0, 0, 1]  \n",
       "112012  US mobile giants in merger talks US mobile ope...  [1, 0, 0, 0]  \n",
       "98506   Sorenstam Ends the Year With Trophy (AP) AP - ...  [0, 0, 1, 0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare the data and split into training and test\n",
    "import numpy as np\n",
    "\n",
    "labels = np.sort(df.label.unique())\n",
    "\n",
    "#perhaps should use floats here...\n",
    "def one_hot_encoding(x, labels):\n",
    "    return [int(l==x) for l in labels]\n",
    "\n",
    "df['labels'] = df['label'].apply(lambda x: one_hot_encoding(x, labels))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a294ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#tokenize the text\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "df['tokenized'] = df['text'].apply(lambda x: tokenizer(x, return_tensors='tf', truncation=True, padding=True))\n",
    "\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tokenized'], df['labels'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59ae2830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118159    [input_ids, attention_mask]\n",
      "9006      [input_ids, attention_mask]\n",
      "104343    [input_ids, attention_mask]\n",
      "108450    [input_ids, attention_mask]\n",
      "107612    [input_ids, attention_mask]\n",
      "Name: tokenized, dtype: object 118159    [0, 0, 0, 1]\n",
      "9006      [0, 0, 0, 1]\n",
      "104343    [1, 0, 0, 0]\n",
      "108450    [0, 0, 1, 0]\n",
      "107612    [0, 1, 0, 0]\n",
      "              ...     \n",
      "101358    [0, 0, 1, 0]\n",
      "3928      [1, 0, 0, 0]\n",
      "110807    [0, 0, 0, 1]\n",
      "35216     [0, 1, 0, 0]\n",
      "87395     [0, 0, 0, 1]\n",
      "Name: labels, Length: 7000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#doesn't feel right\n",
    "print(X_train.head(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reasonable-graph",
   "metadata": {
    "id": "reasonable-graph",
    "outputId": "91af619c-869d-40c0-c8c7-013453b6a022"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig, AdamW\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7711e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a simple model, could increase dropout from 0.1 to 0.2\n",
    "configuration = DistilBertConfig(output_hidden_states=True)\n",
    "#initializing model\n",
    "model = DistilBertForSequenceClassification(config=configuration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-village",
   "metadata": {
    "id": "confident-village"
   },
   "outputs": [],
   "source": [
    "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text\n",
    "\n",
    "DISTILBERT_DROPOUT = 0.2\n",
    "DISTILBERT_ATT_DROPOUT = 0.2\n",
    " \n",
    "# Configure DistilBERT's initialization\n",
    "config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, \n",
    "                          attention_dropout=DISTILBERT_ATT_DROPOUT, \n",
    "                          output_hidden_states=True)\n",
    "                       \n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config = config)\n",
    "#model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-object",
   "metadata": {
    "id": "psychological-object"
   },
   "outputs": [],
   "source": [
    "##TODO print the summary of the model\n",
    "model.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-recommendation",
   "metadata": {
    "id": "statistical-recommendation"
   },
   "outputs": [],
   "source": [
    "##TODO split the sample into a training and a test set \n",
    "##TODO prepare the dataset for torch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-compound",
   "metadata": {
    "id": "piano-compound"
   },
   "outputs": [],
   "source": [
    "##TODO fit the model and print the obtained accuracy (hint: you can follow the training steps in the notebook. To learn more, checkout the trainer class of huggingface transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe3a17",
   "metadata": {
    "id": "e7fe3a17"
   },
   "source": [
    "# Doc Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41f71c",
   "metadata": {
    "id": "3b41f71c"
   },
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "!unzip sts2017.eval.v1.1.zip \n",
    "!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a11ab",
   "metadata": {
    "id": "d48a11ab"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8bcb4",
   "metadata": {
    "id": "dee8bcb4"
   },
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f02f97",
   "metadata": {
    "id": "46f02f97"
   },
   "outputs": [],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965242a5",
   "metadata": {
    "id": "965242a5"
   },
   "outputs": [],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset\n",
    "##TODO derive the word vectors for each text in the dataset\n",
    "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
    "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b67c8",
   "metadata": {
    "id": "e67b67c8"
   },
   "outputs": [],
   "source": [
    "##TODO do the same with embeddings provided by spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf40ced",
   "metadata": {
    "id": "2cf40ced"
   },
   "outputs": [],
   "source": [
    "##TODO do the same with SBERT embeddings"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
