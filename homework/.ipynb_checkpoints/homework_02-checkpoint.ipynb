{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60bffde",
   "metadata": {},
   "source": [
    "# HW02: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed3f1a",
   "metadata": {},
   "source": [
    "Remember that these homework work as a completion grade. **You can skip one section without losing credit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b29ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-06 11:31:17--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29470338 (28M) [text/plain]\n",
      "Saving to: 'train.csv'\n",
      "\n",
      "train.csv           100%[===================>]  28.10M  2.57MB/s    in 8.7s    \n",
      "\n",
      "2023-03-06 11:31:26 (3.22 MB/s) - 'train.csv' saved [29470338/29470338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc19cf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
       "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              title  \\\n",
       "0  business  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "1  business    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "2  business  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "3  business  Oil prices soar to all-time record, posing new...   \n",
       "4  business        Stocks End Up, But Near Year Lows (Reuters)   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Reuters - Private investment firm Carlyle Grou...   \n",
       "1  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "2  Reuters - Authorities have halted oil export\\f...   \n",
       "3  AFP - Tearaway world oil prices, toppling reco...   \n",
       "4  Reuters - Stocks ended slightly higher on Frid...   \n",
       "\n",
       "                                                text  \n",
       "0  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "1  Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
       "2  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "3  Oil prices soar to all-time record, posing new...  \n",
       "4  Stocks End Up, But Near Year Lows (Reuters) Re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the AG news dataset (same as hw01)\n",
    "#Download them from here \n",
    "#!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7b626",
   "metadata": {},
   "source": [
    "## Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab1861a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New\n",
      "Backup\n",
      "Voting\n",
      "System\n",
      "May\n",
      "Pose\n",
      "Problems\n",
      "(\n",
      "AP\n",
      ")\n",
      "AP\n",
      "-\n",
      "Call\n",
      "it\n",
      "the\n",
      "law\n",
      "of\n",
      "unintended\n",
      "consequences\n",
      ".\n",
      "A\n",
      "new\n",
      "national\n",
      "backup\n",
      "system\n",
      "meant\n",
      "to\n",
      "ensure\n",
      "that\n",
      "millions\n",
      "of\n",
      "eligible\n",
      "voters\n",
      "are\n",
      "not\n",
      "mistakenly\n",
      "turned\n",
      "away\n",
      "from\n",
      "the\n",
      "polls\n",
      "this\n",
      "year\n",
      ",\n",
      "as\n",
      "happened\n",
      "in\n",
      "2000\n",
      ",\n",
      "could\n",
      "wind\n",
      "up\n",
      "causing\n",
      "Election\n",
      "Day\n",
      "problems\n",
      "as\n",
      "infamous\n",
      "as\n",
      "Florida\n",
      "'s\n",
      "hanging\n",
      "chads\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#need to download the spacey packages\n",
    "import spacy\n",
    "dfs = df.sample(50)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "##TODO use spacy to split the documents in the sampled dataframe (dfs) in sentences and tokens\n",
    "\n",
    "def tokenizer(print_tok: bool, txt: str):\n",
    "    doc = nlp(txt)\n",
    "    for sent in doc.sents:\n",
    "        if print_tok == False:\n",
    "            print(sent)\n",
    "        else:\n",
    "            for tok in sent:\n",
    "                print(tok)\n",
    "            \n",
    "##TODO print the first sentence of the first document in your sample\n",
    "\n",
    "tokenizer(True, dfs.iloc[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5b2dc83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>[carlyle, looks, commercial, aerospace, reuter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>[oil, economy, cloud, stocks, outlook, reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>[iraq, halts, oil, exports, main, southern, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>[oil, prices, soar, time, record, posing, new,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
       "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
       "      <td>[stocks, end, near, year, lows, reuters, reute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              title  \\\n",
       "0  business  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "1  business    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "2  business  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "3  business  Oil prices soar to all-time record, posing new...   \n",
       "4  business        Stocks End Up, But Near Year Lows (Reuters)   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Reuters - Private investment firm Carlyle Grou...   \n",
       "1  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "2  Reuters - Authorities have halted oil export\\f...   \n",
       "3  AFP - Tearaway world oil prices, toppling reco...   \n",
       "4  Reuters - Stocks ended slightly higher on Frid...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "1  Oil and Economy Cloud Stocks' Outlook (Reuters...   \n",
       "2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "3  Oil prices soar to all-time record, posing new...   \n",
       "4  Stocks End Up, But Near Year Lows (Reuters) Re...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [carlyle, looks, commercial, aerospace, reuter...  \n",
       "1  [oil, economy, cloud, stocks, outlook, reuters...  \n",
       "2  [iraq, halts, oil, exports, main, southern, pi...  \n",
       "3  [oil, prices, soar, time, record, posing, new,...  \n",
       "4  [stocks, end, near, year, lows, reuters, reute...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO create a new column with tokens in lowercase (x.lower()), without punctuation tokens (x.is_punct), \n",
    "#stopwords (x.is_stop), and digits (x.is_digit)\n",
    "\n",
    "#example_df[\"tokens\"] = example_df[\"Text\"].apply(lambda x: [t.text for t in nlp.tokenizer(x)])\n",
    "def tok_func(text):\n",
    "    tok_list = []\n",
    "    for t in nlp.tokenizer(text):\n",
    "        if not(t.is_punct or t.is_stop or t.is_digit):\n",
    "            tok_list.append(t.text.lower())\n",
    "    return tok_list\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: tok_func(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65fa4c48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlyle\n",
      "nsubj\n",
      "--\n",
      "look\n",
      "ROOT\n",
      "--\n",
      "Toward\n",
      "prep\n",
      "--\n",
      "Commercial\n",
      "compound\n",
      "--\n",
      "Aerospace\n",
      "pobj\n",
      "--\n",
      "(\n",
      "punct\n",
      "--\n",
      "Reuters\n",
      "appos\n",
      "--\n",
      ")\n",
      "punct\n",
      "--\n",
      "Reuters\n",
      "npadvmod\n",
      "--\n",
      "-\n",
      "punct\n",
      "--\n",
      "private\n",
      "amod\n",
      "--\n",
      "investment\n",
      "compound\n",
      "--\n",
      "firm\n",
      "compound\n",
      "--\n",
      "Carlyle\n",
      "compound\n",
      "--\n",
      "Group,\\which\n",
      "nsubj\n",
      "--\n",
      "have\n",
      "ccomp\n",
      "--\n",
      "a\n",
      "det\n",
      "--\n",
      "reputation\n",
      "dobj\n",
      "--\n",
      "for\n",
      "prep\n",
      "--\n",
      "make\n",
      "pcomp\n",
      "--\n",
      "well\n",
      "advmod\n",
      "--\n",
      "-\n",
      "punct\n",
      "--\n",
      "time\n",
      "amod\n",
      "--\n",
      "and\n",
      "cc\n",
      "--\n",
      "occasionally\\controversial\n",
      "conj\n",
      "--\n",
      "play\n",
      "dobj\n",
      "--\n",
      "in\n",
      "prep\n",
      "--\n",
      "the\n",
      "det\n",
      "--\n",
      "defense\n",
      "compound\n",
      "--\n",
      "industry\n",
      "pobj\n",
      "--\n",
      ",\n",
      "punct\n",
      "--\n",
      "have\n",
      "aux\n",
      "--\n",
      "quietly\n",
      "advmod\n",
      "--\n",
      "placed\\it\n",
      "conj\n",
      "--\n",
      "bet\n",
      "dobj\n",
      "--\n",
      "on\n",
      "prep\n",
      "--\n",
      "another\n",
      "det\n",
      "--\n",
      "part\n",
      "pobj\n",
      "--\n",
      "of\n",
      "prep\n",
      "--\n",
      "the\n",
      "det\n",
      "--\n",
      "market\n",
      "pobj\n",
      "--\n",
      ".\n",
      "punct\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "##TODO print the tokens (x.lemma_) and the dependency labels (x.dep_ ) of the first sentence of the first \n",
    "#document (doc.sents)\n",
    "\n",
    "for x in nlp(df.iloc[0,3]):\n",
    "    print(x.lemma_)\n",
    "    print(x.dep_)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef544f1",
   "metadata": {},
   "source": [
    "### Named Entities\n",
    "\n",
    "Let's compute the ratio of named entities starting with a capital letter, e.g. if we have \"University of Chicago\" as a NE, \"University\" and \"Chicago\" are capitalized, \"of\" is not, thus the ratio is 2/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be2cb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "University of Chicago\n",
      "False\n",
      "Stanford\n"
     ]
    }
   ],
   "source": [
    "##TODO print the ratio of tokens being part of a named entity span starting with a capital letter (doc.ents)\n",
    "doc = nlp('University of Chicago is ver nice Stanford')\n",
    "for ent in doc.ents:\n",
    "    for t in ent:\n",
    "        print(t.text.isupper())\n",
    "    print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85bf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO print the ratio of capitalized tokens not being part of a named entity span (have no token.ent_type_)\n",
    "# e.g. \"The dog barks\" = 1/3; 3 tokens, only \"The\" is capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ede3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO print the ratio of capitalized tokens not being a named entity and not being the first token in a sentence\n",
    "# e.g. \"The dog barks\" = 0; 3 tokens, \"The\" is capitalized but the starting token of a sentence, no other tokens are capitalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466753be",
   "metadata": {},
   "source": [
    "Give an example of a capitalized token in the data which is neither a named entity nor at the start of a sentence. What could be the reason the token is capitalized (one sentence)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c0a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3126a5c7",
   "metadata": {},
   "source": [
    "## Term Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055edce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=0.01, \n",
    "                        max_df=0.9,  \n",
    "                        max_features=1000,\n",
    "                        stop_words='english',\n",
    "                        use_idf=True, # the new piece\n",
    "                        ngram_range=(1,2))\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##TODO using the whole sample, produce a world cloud with bigrams for label == business using tfidf frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948e50f",
   "metadata": {},
   "source": [
    "## Supervised Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "##TODO compute the number of words per document (excluding stopwords)\n",
    "##TODO get the most predictive features of the number of words per document using first f_class and then chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaee2e4",
   "metadata": {},
   "source": [
    "Are the results different? What could be a reason for this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af74a1d",
   "metadata": {},
   "source": [
    "## Huggingface Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e75e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we use distilbert tokenizer\n",
    "# !pip install transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "# let's instantiate a tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "##TODO tokenize the sentences in the sampled dataframe (dfs) using the DisilBertTokenizer\n",
    "##TODO what is the type/token ratio from this tokenizer (number_of_unqiue_token_types/number_of_tokens)?\n",
    "##TODO what is the amount of subword tokens returned by the huggingface tokenizer? hint: each subword token starts with \"#\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc9d00",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16bf8639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110581</th>\n",
       "      <td>sport</td>\n",
       "      <td>UEFA to probe Valencia-Werder Bremen incidents</td>\n",
       "      <td>UEFA will be launching disciplinary proceeding...</td>\n",
       "      <td>UEFA to probe Valencia-Werder Bremen incidents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>New iMac tries to play it cool</td>\n",
       "      <td>Hot G5 chip requires some serious effort to av...</td>\n",
       "      <td>New iMac tries to play it cool Hot G5 chip req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>business</td>\n",
       "      <td>Ford Reports Disappointing U.S. Sales</td>\n",
       "      <td>Ford's car and truck business sales fell nearl...</td>\n",
       "      <td>Ford Reports Disappointing U.S. Sales Ford's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57350</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Microsoft Upgrades Windows XP Media Center (Ne...</td>\n",
       "      <td>NewsFactor - Bill Gates is about to announce a...</td>\n",
       "      <td>Microsoft Upgrades Windows XP Media Center (Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90601</th>\n",
       "      <td>sport</td>\n",
       "      <td>Rams make statement they #39;re team to beat i...</td>\n",
       "      <td>ST. LOUIS -- When St. Louis coach Mike Martz l...</td>\n",
       "      <td>Rams make statement they #39;re team to beat i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                              title  \\\n",
       "110581     sport     UEFA to probe Valencia-Werder Bremen incidents   \n",
       "15925   sci/tech                     New iMac tries to play it cool   \n",
       "46720   business              Ford Reports Disappointing U.S. Sales   \n",
       "57350   sci/tech  Microsoft Upgrades Windows XP Media Center (Ne...   \n",
       "90601      sport  Rams make statement they #39;re team to beat i...   \n",
       "\n",
       "                                                     lead  \\\n",
       "110581  UEFA will be launching disciplinary proceeding...   \n",
       "15925   Hot G5 chip requires some serious effort to av...   \n",
       "46720   Ford's car and truck business sales fell nearl...   \n",
       "57350   NewsFactor - Bill Gates is about to announce a...   \n",
       "90601   ST. LOUIS -- When St. Louis coach Mike Martz l...   \n",
       "\n",
       "                                                     text  \n",
       "110581  UEFA to probe Valencia-Werder Bremen incidents...  \n",
       "15925   New iMac tries to play it cool Hot G5 chip req...  \n",
       "46720   Ford Reports Disappointing U.S. Sales Ford's c...  \n",
       "57350   Microsoft Upgrades Windows XP Media Center (Ne...  \n",
       "90601   Rams make statement they #39;re team to beat i...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ec5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#TODO preprocess the corpus using spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ae310",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_pairs(sent):\n",
    "    subjs = [w for w in sent if w.dep_ == \"nsubj\"]\n",
    "    pairs = [(w.lemma_.lower(), w.head.lemma_.lower()) for w in subjs]\n",
    "    return pairs\n",
    "##TODO extract the subject-verbs pairs and print the result for the second document\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c30e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same for verbs-object pairs ('dobj')\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad55039",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same for adjectives-nouns pairs ('amod')\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1273253",
   "metadata": {},
   "source": [
    "### Exploring cross label dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d19500",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO extract all the subject-verbs and verbs-object pairs for the verb \"rise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75649d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO for each label create a list ranking the most common subject-verbs pairs and one for the most common verbs-object pairs\n",
    "##TODO print the 10 most common pairs for each of the two lists for the labels \"world\" and \"sci/tech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d363b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d73fbafa1c1ce4c8cd6f07277ecbf2d62d7720c8bfdb6bdbaeeaf6dba6dd25dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
