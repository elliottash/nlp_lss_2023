{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba611b5",
   "metadata": {},
   "source": [
    "# Week 10: Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61002077",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc138ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:56:16.666501Z",
     "start_time": "2022-03-22T21:56:16.361670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 819\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   case_name       768 non-null    object        \n",
      " 1   opinion_type    768 non-null    object        \n",
      " 2   date_standard   768 non-null    datetime64[ns]\n",
      " 3   authorship      768 non-null    object        \n",
      " 4   x_republican    768 non-null    float64       \n",
      " 5   maj_judges      768 non-null    object        \n",
      " 6   dissent_judges  768 non-null    object        \n",
      " 7   topic_id        768 non-null    float64       \n",
      " 8   cite_count      768 non-null    float64       \n",
      " 9   opinion_text    768 non-null    object        \n",
      " 10  year            768 non-null    int64         \n",
      " 11  log_cite_count  768 non-null    float64       \n",
      " 12  author_id       768 non-null    int8          \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), int8(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('sc_cases_cleaned.pkl', compression='gzip')\n",
    "df = df.assign(author_id=(df['authorship']).astype('category').cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff560738",
   "metadata": {},
   "source": [
    "# GPT-2 and Language Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb6c226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:58:04.691248Z",
     "start_time": "2022-03-22T21:57:33.578606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909f1782ef9a41a38f47fc2a9912f69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a5f7efbfa9419a89edfa5d6965d7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c22b5597ee436b86cb936d124d3f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1225bf14cf7946a597d90fe077ec8275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83907c56aec340c5bf16b94779095a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load GPT2\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fcab8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:58:07.065104Z",
     "start_time": "2022-03-22T21:58:04.692669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating and sharing my own ideas and ideas for the future. I'm always looking for new ways to make my life better. I'm always looking for ways to make my life better.\n",
      "\n",
      "I'm always looking for ways to make my\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('I enjoy generating', return_tensors='pt')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a55ae9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:58:08.209703Z",
     "start_time": "2022-03-22T21:58:07.065860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating my own content, so I'm always looking for ways to improve it.\n",
      "\n",
      "If you have any questions or comments, feel free to leave them in the comments below.\n"
     ]
    }
   ],
   "source": [
    "# activate beam search and early_stopping\n",
    "\n",
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, # to avoid repetitions of the same word sequences\n",
    "    early_stopping=True\n",
    ")\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb4d056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:58:09.140332Z",
     "start_time": "2022-03-22T21:58:08.210899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating more information (aka lower efficiency when we do so) and am doing this right now because it's so genuinely empowering to so many developers, is what makes me feel passionate about this series; that actually provides benefits to the performance of the\n"
     ]
    }
   ],
   "source": [
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123c370e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:58:10.280668Z",
     "start_time": "2022-03-22T21:58:09.141080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating company-wide consensus like this is a pleasant experience, where just one or two guys want to share in the optimism, love and belief without necessarily being wrong.\n",
      "\n",
      "Leadership and people can also back their projects as a good practice\n"
     ]
    }
   ],
   "source": [
    "# sample only from 92% most likely words\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n",
    "# arguably the best generation technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6c864",
   "metadata": {},
   "source": [
    "**GPTNeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9117d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:59:00.900108Z",
     "start_time": "2022-03-22T21:58:35.986370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45de81e39ea84c8fab4a4f842dfd0452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394a4445b3fe4711a2306a0307673e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184dcee59acf42ca928dd2df29833105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d513416419614fc8acaea445c2d0d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37fea1ee3f343a1af14e53ed52c8fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6706f47593478eaef783bf3c850d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating script on command line tools / pasted. a iam.htm is well known in the world, its good for good functioning and your site will allow you to save it automatically. right click on page title of iam.htm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "input_ids = tokenizer.encode('I enjoy generating', return_tensors='pt')\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448beb5",
   "metadata": {},
   "source": [
    "**Conditional Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbbb58eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:59:02.102500Z",
     "start_time": "2022-03-22T21:59:00.901275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump: Mr. Roger Stone is “a right-wing man” who wants to be “not a lawyer,” “not a politician.” I know he sees you’re making a mistake; I\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Donald Trump:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87837832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:59:03.281896Z",
     "start_time": "2022-03-22T21:59:02.103282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden: Vote for the One - 4/35/2012\n",
      "\n",
      "MIAMI (AP) -- Vice President Joe Biden is advancing a new effort to bring up a bill that also prevents all ticket voting. That bill will no longer be called a\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Joe Biden:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10504a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:59:06.731227Z",
     "start_time": "2022-03-22T21:59:05.640904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justice Ruth Bader Ginsburg: Awardrobe Night Ralls Days\n",
      "\n",
      "$9.00\n",
      "\n",
      "Brushbone Ball Set (GMAZ It’s Promised $9.00, not the “later” price\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Justice Ruth Bader Ginsburg:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65169faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
