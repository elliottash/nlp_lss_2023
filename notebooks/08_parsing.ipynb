{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "df = pd.read_csv('death-penalty-cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Science cannot solve the ultimate mystery of nature. And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve.'\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science cannot solve the ultimate mystery of nature. And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Science cannot solve the ultimate mystery of nature.\n",
      "root: solve\n",
      "[(Science, 'nsubj'), (can, 'aux'), (not, 'neg'), (mystery, 'dobj'), (., 'punct')]\n",
      "\n",
      "sentence: And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve.\n",
      "root: is\n",
      "[(And, 'cc'), (that, 'nsubj'), (are, 'advcl'), (., 'punct')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(\"sentence:\", sent)\n",
    "    print(\"root:\", sent.root)\n",
    "    print([(w, w.dep_) for w in sent.root.children])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current sentence\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Science,\n",
       " the ultimate mystery,\n",
       " nature,\n",
       " the last analysis,\n",
       " we,\n",
       " ourselves,\n",
       " a part,\n",
       " the mystery,\n",
       " we]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noun Phrase Chunking\n",
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[And, that, are, .]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sent.root.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[And, that]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left children\n",
    "list(sent.root.lefts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[are, .]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right children\n",
    "list(sent.root.rights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "And"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first token\n",
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first token dependency label, cc=conjunction\n",
    "sent[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0].head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Discovery of Gendered Language through Latent-Variable Modeling\n",
    "\n",
    "[Hoyle et al. (2019)](https://www.aclweb.org/anthology/P19-1167/) study the language use of gendered nouns and proceed to train a generative latent-variable model that jointly represents adjective (or verb) choice, with its sentiment given the (natural) gender of a noun. To this extent, they extract noun–adjectives pairs, NSUBJ–verb pairs and DOBJ–verb pairs. \n",
    "\n",
    "In the following, we show how to extract NSUBJ-verb pairs from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>dateFiled</th>\n",
       "      <th>citeCount</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965-09-14T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>N.J.   ( )\\n  A. d  \\nIN RE WAIVER OF DEATH PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fla</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>1973</td>\n",
       "      <td>1973-07-26T00:00:00Z</td>\n",
       "      <td>552</td>\n",
       "      <td>whether the death penalty is, per se, unconsti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texcrimapp</td>\n",
       "      <td>5765.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>1975</td>\n",
       "      <td>1975-04-16T00:00:00Z</td>\n",
       "      <td>143</td>\n",
       "      <td># ;s contention that the assessment of the dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-11-30T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>. d   ( )\\n -NMSC- \\nIN THE MATTER OF DEATH PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>texcrimapp</td>\n",
       "      <td>5758.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944-12-20T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>assume the district attorney orally waived the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32562</th>\n",
       "      <td>ohioctapp</td>\n",
       "      <td>8055.0</td>\n",
       "      <td>OH</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-07-20T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>of two counts of aggravated murder with deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32563</th>\n",
       "      <td>cal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-07-20T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>his general views about the death penalty as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32564</th>\n",
       "      <td>neb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-07-21T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>been subject to the death\\npenalty, because Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32565</th>\n",
       "      <td>ohio</td>\n",
       "      <td>5374.0</td>\n",
       "      <td>OH</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-07-25T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>that Indiana law permits imposition of the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32566</th>\n",
       "      <td>tenncrimapp</td>\n",
       "      <td>8291.0</td>\n",
       "      <td>TN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-07-20T00:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>original guilty\\nplea for which he received th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32567 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          court_id  author_id state  year             dateFiled  citeCount  \\\n",
       "0               nj        NaN    NJ  1965  1965-09-14T00:00:00Z          8   \n",
       "1              fla     4019.0    FL  1973  1973-07-26T00:00:00Z        552   \n",
       "2       texcrimapp     5765.0    TX  1975  1975-04-16T00:00:00Z        143   \n",
       "3               nm        NaN    NM  2009  2009-11-30T00:00:00Z          0   \n",
       "4       texcrimapp     5758.0    TX  1944  1944-12-20T00:00:00Z         56   \n",
       "...            ...        ...   ...   ...                   ...        ...   \n",
       "32562    ohioctapp     8055.0    OH  2017  2017-07-20T00:00:00Z          0   \n",
       "32563          cal        NaN    CA  2017  2017-07-20T00:00:00Z          0   \n",
       "32564          neb        NaN    NE  2017  2017-07-21T00:00:00Z          0   \n",
       "32565         ohio     5374.0    OH  2017  2017-07-25T00:00:00Z          0   \n",
       "32566  tenncrimapp     8291.0    TN  2017  2017-07-20T00:00:00Z          0   \n",
       "\n",
       "                                                 snippet  \n",
       "0      N.J.   ( )\\n  A. d  \\nIN RE WAIVER OF DEATH PE...  \n",
       "1      whether the death penalty is, per se, unconsti...  \n",
       "2      # ;s contention that the assessment of the dea...  \n",
       "3      . d   ( )\\n -NMSC- \\nIN THE MATTER OF DEATH PE...  \n",
       "4      assume the district attorney orally waived the...  \n",
       "...                                                  ...  \n",
       "32562    of two counts of aggravated murder with deat...  \n",
       "32563   his general views about the death penalty as ...  \n",
       "32564  been subject to the death\\npenalty, because Ne...  \n",
       "32565   that Indiana law permits imposition of the de...  \n",
       "32566  original guilty\\nplea for which he received th...  \n",
       "\n",
       "[32567 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=2000)\n",
    "df[\"processed\"] = df[\"snippet\"].apply(lambda x: nlp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_pairs(sent):\n",
    "    subjs = [w for w in sent if w.dep_ == \"nsubj\"]\n",
    "    pairs = [(w.lemma_.lower(), w.head.lemma_.lower()) for w in subjs]\n",
    "    return pairs\n",
    "\n",
    "df[\"subj-verb-pairs\"] = df[\"processed\"].apply(lambda x: extract_subject_verb_pairs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('penalty', 'be') 229\n",
      "('-pron-', 'be') 202\n",
      "('state', 'seek') 144\n",
      "('this', 'be') 67\n",
      "('-pron-', 'have') 59\n",
      "('-pron-', 'vote') 58\n",
      "('jury', 'recommend') 49\n",
      "('-pron-', 'impose') 45\n",
      "('statute', 'be') 43\n",
      "('court', 'find') 36\n",
      "('-pron-', 'find') 36\n",
      "('defendant', 'be') 34\n",
      "('jury', 'find') 34\n",
      "('-pron-', 'seek') 33\n",
      "('that', 'be') 31\n",
      "('jury', 'impose') 30\n",
      "('court', 'impose') 29\n",
      "('court', 'hold') 28\n",
      "('-pron-', 'give') 28\n",
      "('-pron-', 'do') 28\n",
      "('-pron-', 'believe') 26\n",
      "('defendant', 'eligible') 25\n",
      "('-pron-', 'consider') 25\n",
      "('imposition', 'be') 24\n",
      "('who', 'be') 23\n"
     ]
    }
   ],
   "source": [
    "# most common pairs\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for item in df[\"subj-verb-pairs\"]:\n",
    "    counter.update(item)\n",
    "    \n",
    "for pair, counts in counter.most_common(n=25):\n",
    "    print (pair, counts) # -pron- is a pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'neuralcoref' already exists and is not an empty directory.\n",
      "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from -r neuralcoref/requirements.txt (line 1)) (2.3.5)\n",
      "Requirement already satisfied: cython>=0.25 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from -r neuralcoref/requirements.txt (line 2)) (0.29.22)\n",
      "Requirement already satisfied: pytest in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from -r neuralcoref/requirements.txt (line 3)) (6.2.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (4.56.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (2.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (7.4.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r neuralcoref/requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: packaging in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (20.9)\n",
      "Requirement already satisfied: iniconfig in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: toml in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (0.10.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (20.3.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from pytest->-r neuralcoref/requirements.txt (line 3)) (1.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from packaging->pytest->-r neuralcoref/requirements.txt (line 3)) (2.4.7)\n",
      "Obtaining file:///home/dominsta/Dropbox/2021-02-Legal-DNA/legal_dna_2021/notebooks/neuralcoref\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from neuralcoref==4.0) (1.19.5)\n",
      "Requirement already satisfied: boto3 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from neuralcoref==4.0) (1.17.49)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from neuralcoref==4.0) (2.25.1)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from neuralcoref==4.0) (2.3.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (4.56.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (7.4.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (2.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref==4.0) (3.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref==4.0) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref==4.0) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from boto3->neuralcoref==4.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.49 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from boto3->neuralcoref==4.0) (1.20.49)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from boto3->neuralcoref==4.0) (0.3.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.49->boto3->neuralcoref==4.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/dominsta/anaconda3/envs/legal_dna/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.49->boto3->neuralcoref==4.0) (1.15.0)\n",
      "Installing collected packages: neuralcoref\n",
      "  Attempting uninstall: neuralcoref\n",
      "    Found existing installation: neuralcoref 4.0\n",
      "    Uninstalling neuralcoref-4.0:\n",
      "      Successfully uninstalled neuralcoref-4.0\n",
      "  Running setup.py develop for neuralcoref\n",
      "Successfully installed neuralcoref\n"
     ]
    }
   ],
   "source": [
    "# install coreference resolution for spacy\n",
    "!current_dir==$(pwd)\n",
    "!cd\n",
    "!git clone https://github.com/huggingface/neuralcoref.git\n",
    "!cd neuralcoref\n",
    "!pip install -r neuralcoref/requirements.txt\n",
    "!pip install -e neuralcoref\n",
    "!cd $current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fcc5d70be10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up coreference resolution\n",
    "import neuralcoref      ## ignore RuntimeWarning(s)\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[My sister: [My sister, She], a dog: [a dog, him]]\n",
      "My sister has a dog. My sister loves a dog.\n"
     ]
    }
   ],
   "source": [
    "# Coreference Resolution\n",
    "doc = nlp(u'My sister has a dog. She loves him.')\n",
    "print(doc._.has_coref)         ## True\n",
    "print(doc._.coref_clusters)    ## [My sister: [My sister, She], a dog: [a dog, him]]\n",
    "print(doc._.coref_resolved)    ## 'My sister has a dog. My sister loves a dog.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"corefs_resolved\"] = df[\"snippet\"].apply(lambda x: nlp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_pairs_coref(sent):\n",
    "    subjs = [w for w in sent if w.dep_ == \"nsubj\"]\n",
    "    pairs = []\n",
    "    for w in subjs:\n",
    "        # either a subject is part of a coreference chain, then we need to resolve the chain\n",
    "        if w._.in_coref:\n",
    "            cluster = w._.coref_clusters[0]\n",
    "            lemma = cluster.main.root.lemma_.lower()\n",
    "            pairs.append((lemma, w.head.lemma_.lower()))\n",
    "        # if it's not, we can just do the same as above\n",
    "        else:\n",
    "            pairs.append((w.lemma_.lower(), w.head.lemma_.lower()))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('penalty', 'be') 237\n",
      "('state', 'seek') 146\n",
      "('-pron-', 'be') 145\n",
      "('this', 'be') 67\n",
      "('jury', 'recommend') 48\n",
      "('-pron-', 'have') 45\n",
      "('-pron-', 'vote') 45\n",
      "('statute', 'be') 43\n",
      "('defendant', 'be') 40\n",
      "('court', 'find') 36\n",
      "('jury', 'find') 34\n",
      "('that', 'be') 31\n",
      "('court', 'impose') 31\n",
      "('jury', 'impose') 30\n",
      "('-pron-', 'find') 30\n",
      "('court', 'hold') 28\n",
      "('-pron-', 'impose') 26\n",
      "('defendant', 'eligible') 25\n",
      "('imposition', 'be') 24\n",
      "('-pron-', 'seek') 24\n",
      "('-pron-', 'consider') 23\n",
      "('court', 'sentence') 22\n",
      "('case', 'be') 22\n",
      "('who', 'be') 22\n",
      "('-pron-', 'hold') 21\n"
     ]
    }
   ],
   "source": [
    "df[\"subj-verb-pairs-coref\"] = df[\"corefs_resolved\"].apply(lambda x: extract_subject_verb_pairs_coref(x))\n",
    "counter = Counter()\n",
    "for item in df[\"subj-verb-pairs-coref\"]:\n",
    "    counter.update(item)\n",
    "    \n",
    "for pair, counts in counter.most_common(n=25):\n",
    "    print (pair, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defendant be 40\n",
      "defendant eligible 25\n",
      "defendant contend 16\n",
      "defendant receive 14\n",
      "defendant argue 11\n",
      "defendant have 9\n",
      "defendant s 8\n",
      "defendant raise 7\n",
      "defendant file 5\n",
      "defendant waive 4\n",
      "defendant guilty 4\n",
      "defendant make 4\n",
      "defendant claim 4\n",
      "defendant challenge 3\n",
      "defendant allege 3\n",
      "defendant rely 2\n",
      "defendant face 2\n",
      "defendant appeal 2\n",
      "defendant could 2\n",
      "defendant escape 2\n",
      "defendant assert 2\n",
      "defendant move 2\n",
      "defendant avoid 2\n",
      "defendant acknowledge 2\n",
      "defendant hold 2\n",
      "defendant assign 2\n",
      "defendant indicate 2\n",
      "defendant get 2\n",
      "defendant deserve 2\n",
      "defendant state 2\n",
      "defendant learn 2\n"
     ]
    }
   ],
   "source": [
    "# verbs used with defendant\n",
    "\n",
    "for (subject, verb), counts in counter.most_common():\n",
    "    if subject == \"defendant\" and counts > 1:\n",
    "        print (subject, verb, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jury recommend 48\n",
      "jury find 34\n",
      "jury impose 30\n",
      "jury be 17\n",
      "jury return 6\n",
      "jury consider 6\n",
      "jury vote 5\n",
      "jury convict 4\n",
      "jury assess 4\n",
      "jury decline 4\n",
      "jury decide 4\n",
      "jury answer 4\n",
      "jury s 3\n",
      "jury make 3\n",
      "jury abuse 2\n",
      "jury inflict 2\n",
      "jury charge 2\n",
      "jury determine 2\n",
      "jury do 2\n",
      "jury reject 2\n",
      "jury fix 2\n",
      "jury have 2\n"
     ]
    }
   ],
   "source": [
    "# verbs used with jury\n",
    "\n",
    "for (subject, verb), counts in counter.most_common():\n",
    "    if subject == \"jury\" and counts > 1:\n",
    "        print (subject, verb, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
