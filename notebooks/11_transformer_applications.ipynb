{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-velvet",
   "metadata": {},
   "source": [
    "# Week 11: Transformers Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-louisiana",
   "metadata": {},
   "source": [
    "Additional references: \n",
    "- [Question Answering with huggingface](https://huggingface.co/transformers/usage.html)\n",
    "- [Textual Entailment](https://nlp.stanford.edu/pubs/snli_paper.pdf)\n",
    "- [SQuAD question answering](https://arxiv.org/abs/1606.05250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earlier-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 819\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   case_name       768 non-null    object        \n",
      " 1   opinion_type    768 non-null    object        \n",
      " 2   date_standard   768 non-null    datetime64[ns]\n",
      " 3   authorship      768 non-null    object        \n",
      " 4   x_republican    768 non-null    float64       \n",
      " 5   maj_judges      768 non-null    object        \n",
      " 6   dissent_judges  768 non-null    object        \n",
      " 7   topic_id        768 non-null    float64       \n",
      " 8   cite_count      768 non-null    float64       \n",
      " 9   opinion_text    768 non-null    object        \n",
      " 10  year            768 non-null    int64         \n",
      " 11  log_cite_count  768 non-null    float64       \n",
      " 12  author_id       768 non-null    int8          \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), int8(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('sc_cases_cleaned.pkl', compression='gzip')\n",
    "df = df.assign(author_id=(df['authorship']).astype('category').cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "awful-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated cache directory found (/home/dominsta/.allennlp/datasets).  Please remove this directory from your system to free up space.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz\")\n",
    "predictions = predictor.predict(\n",
    "    document=\"Paul Allen was born on January 21, 1953, in Seattle, Washington, to Kenneth Sam Allen and Edna Faye Allen. Allen attended Lakeside School, a private school in Seattle, where he befriended Bill Gates, two years younger, with whom he shared an enthusiasm for computers.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_spans': [[0, 1],\n",
       "  [3, 3],\n",
       "  [5, 8],\n",
       "  [5, 14],\n",
       "  [8, 8],\n",
       "  [11, 13],\n",
       "  [11, 14],\n",
       "  [13, 13],\n",
       "  [16, 18],\n",
       "  [16, 22],\n",
       "  [20, 22],\n",
       "  [24, 24],\n",
       "  [26, 52],\n",
       "  [33, 33],\n",
       "  [36, 36],\n",
       "  [37, 37],\n",
       "  [38, 52],\n",
       "  [41, 42],\n",
       "  [47, 47],\n",
       "  [48, 48],\n",
       "  [49, 52]],\n",
       " 'antecedent_indices': [[0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]],\n",
       " 'predicted_antecedents': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  0,\n",
       "  -1,\n",
       "  5,\n",
       "  11,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  11,\n",
       "  -1,\n",
       "  -1],\n",
       " 'document': ['Paul',\n",
       "  'Allen',\n",
       "  'was',\n",
       "  'born',\n",
       "  'on',\n",
       "  'January',\n",
       "  '21',\n",
       "  ',',\n",
       "  '1953',\n",
       "  ',',\n",
       "  'in',\n",
       "  'Seattle',\n",
       "  ',',\n",
       "  'Washington',\n",
       "  ',',\n",
       "  'to',\n",
       "  'Kenneth',\n",
       "  'Sam',\n",
       "  'Allen',\n",
       "  'and',\n",
       "  'Edna',\n",
       "  'Faye',\n",
       "  'Allen',\n",
       "  '.',\n",
       "  'Allen',\n",
       "  'attended',\n",
       "  'Lakeside',\n",
       "  'School',\n",
       "  ',',\n",
       "  'a',\n",
       "  'private',\n",
       "  'school',\n",
       "  'in',\n",
       "  'Seattle',\n",
       "  ',',\n",
       "  'where',\n",
       "  'he',\n",
       "  'befriended',\n",
       "  'Bill',\n",
       "  'Gates',\n",
       "  ',',\n",
       "  'two',\n",
       "  'years',\n",
       "  'younger',\n",
       "  ',',\n",
       "  'with',\n",
       "  'whom',\n",
       "  'he',\n",
       "  'shared',\n",
       "  'an',\n",
       "  'enthusiasm',\n",
       "  'for',\n",
       "  'computers',\n",
       "  '.'],\n",
       " 'clusters': [[[0, 1], [24, 24], [36, 36], [47, 47]], [[11, 13], [33, 33]]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "characteristic-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Paul', 'Allen', 'was', 'born', 'on', 'January', '21', ',', '1953', ','],\n",
       " [[[0, 1], [24, 24], [36, 36], [47, 47]], [[11, 13], [33, 33]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = predictions['clusters']\n",
    "document = predictions['document']\n",
    "document[:10], clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-sound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Paul',\n",
       " 1: 'Allen',\n",
       " 2: 'was',\n",
       " 3: 'born',\n",
       " 4: 'on',\n",
       " 5: 'January',\n",
       " 6: '21',\n",
       " 7: ',',\n",
       " 8: '1953',\n",
       " 9: ',',\n",
       " 10: 'in',\n",
       " 11: 'Seattle',\n",
       " 12: ',',\n",
       " 13: 'Washington',\n",
       " 14: ',',\n",
       " 15: 'to',\n",
       " 16: 'Kenneth',\n",
       " 17: 'Sam',\n",
       " 18: 'Allen',\n",
       " 19: 'and',\n",
       " 20: 'Edna',\n",
       " 21: 'Faye',\n",
       " 22: 'Allen',\n",
       " 23: '.',\n",
       " 24: 'Allen',\n",
       " 25: 'attended',\n",
       " 26: 'Lakeside',\n",
       " 27: 'School',\n",
       " 28: ',',\n",
       " 29: 'a',\n",
       " 30: 'private',\n",
       " 31: 'school',\n",
       " 32: 'in',\n",
       " 33: 'Seattle',\n",
       " 34: ',',\n",
       " 35: 'where',\n",
       " 36: 'he',\n",
       " 37: 'befriended',\n",
       " 38: 'Bill',\n",
       " 39: 'Gates',\n",
       " 40: ',',\n",
       " 41: 'two',\n",
       " 42: 'years',\n",
       " 43: 'younger',\n",
       " 44: ',',\n",
       " 45: 'with',\n",
       " 46: 'whom',\n",
       " 47: 'he',\n",
       " 48: 'shared',\n",
       " 49: 'an',\n",
       " 50: 'enthusiasm',\n",
       " 51: 'for',\n",
       " 52: 'computers',\n",
       " 53: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "doc = {}\n",
    "for obj in document:    \n",
    "    doc.update({n :  obj}) #creating a dictionary of each word with its respective index\n",
    "    n = n+1\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Paul', 'Allen', 'Allen', 'he', 'he'], ['Seattle', ',', 'Washington', 'Seattle']]\n"
     ]
    }
   ],
   "source": [
    "clus_all = []\n",
    "cluster = []\n",
    "clus_one = {}\n",
    "for i in range(0, len(clusters)):    \n",
    "    one_cl = clusters[i]    \n",
    "    for count in range(0, len(one_cl)):           \n",
    "        obj = one_cl[count]        \n",
    "        for num in range((obj[0]), (obj[1]+1)):            \n",
    "            for n in doc:                \n",
    "                if num == n:                 \n",
    "                    cluster.append(doc[n]) \n",
    "    clus_all.append(cluster)       \n",
    "    cluster = []\n",
    "    \n",
    "print(clus_all) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-testament",
   "metadata": {},
   "source": [
    "**Question Answering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forty-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6222437024116516, 'start': 34, 'end': 95, 'answer': 'the task of extracting an answer from a text given a question'}\n",
      "{'score': 0.5115309357643127, 'start': 147, 'end': 160, 'answer': 'SQuAD dataset'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the `run_squad.py`.\n",
    "\"\"\"\n",
    "\n",
    "print(nlp(question=\"What is extractive question answering?\", context=context))\n",
    "print(nlp(question=\"What is a good example of a question answering dataset?\", context=context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-taste",
   "metadata": {},
   "source": [
    "**Textual Entailment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vietnamese-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using AllenNLP\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/decomposable-attention-elmo-2020.04.09.tar.gz\")\n",
    "prediction = predictor.predict(\n",
    "    premise=\"Two women are wandering along the shore drinking iced tea.\",\n",
    "    hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00033908788464032114, 0.9735872745513916, 0.02607356198132038]\n",
      "Contradiction\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "id2label = {0:\"Entailment\", 1:\"Contradiction\", 2:\"Neutral\"} # https://demo.allennlp.org/textual-entailment/elmo-snli\n",
    "print (prediction[\"label_probs\"])\n",
    "print (id2label[np.argmax(prediction[\"label_probs\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# using Transformers\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "model_name = \"roberta-large-mnli\" # mnli refers to the following dataset on which roberta was trained: https://cims.nyu.edu/~sbowman/multinli/\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latin-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Two women are wandering along the shore drinking iced tea.</s></s>Two women are sitting on a blanket near some rocks talking about politics.</s>\n"
     ]
    }
   ],
   "source": [
    "premise=\"Two women are wandering along the shore drinking iced tea.\"\n",
    "hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    "\n",
    "model_input = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "print (tokenizer.decode(model_input[\"input_ids\"][0]))\n",
    "# note how we obtain a single sequence with <s>premise</s></s>hypothesis</s>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focused-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "import torch\n",
    "\n",
    "output = model(**model_input)\n",
    "softmax = Softmax()\n",
    "probs = softmax(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "protecting-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8877, 0.1107, 0.0016]], grad_fn=<SoftmaxBackward>)\n",
      "Contradiction\n"
     ]
    }
   ],
   "source": [
    "print (probs)\n",
    "\n",
    "id2label = {0:\"Contradiction\", 1:\"Neutral\", 2:\"Entailment\"} # these are label2id from MNLI\n",
    "\n",
    "argmax = torch.argmax(output.logits[0].detach()).item()\n",
    "print (id2label[argmax])\n",
    "\n",
    "#print (id2label[torch.argmax(output.logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metallic-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it for a whole batch\n",
    "\n",
    "premises = [\"If you help the needy, God will reward you.\", \"An interplanetary spacecraft is in orbit around a gas giant's icy moon.\", \"A large, gray elephant walked beside a herd of zebras.\", \"A handmade djembe was on display at the Smithsonian.\"]\n",
    "hypotheses = [\"Giving money to the poor has good consequences.\", \"The spacecraft has the ability to travel between planets.\", \"The elephant was lost.\", \"Visitors could see the djembe.\"] \n",
    "\n",
    "model_inputs = tokenizer(premises, hypotheses, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "characteristic-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you help the needy, God will reward you. -- Giving money to the poor has good consequences. -- Entailment\n",
      "An interplanetary spacecraft is in orbit around a gas giant's icy moon. -- The spacecraft has the ability to travel between planets. -- Neutral\n",
      "A large, gray elephant walked beside a herd of zebras. -- The elephant was lost. -- Neutral\n",
      "A handmade djembe was on display at the Smithsonian. -- Visitors could see the djembe. -- Entailment\n"
     ]
    }
   ],
   "source": [
    "output = model(**model_inputs)\n",
    "softmax = Softmax()\n",
    "probs = softmax(output.logits)\n",
    "\n",
    "for premise, hypothesis, prediction in zip(premises, hypotheses, probs):\n",
    "    argmax = torch.argmax(prediction).item()\n",
    "    print (premise, \"--\", hypothesis, \"--\", id2label[argmax])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
